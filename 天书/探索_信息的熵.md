# 信息的熵

> *"完美的记录不包含任何信息，因为它不排除任何可能性。知识的本质是排除，理解的本质是选择。包含一切者理解虚无。"*
>
> ——阿尔-哈桑·伊本·海什木，《光书》第七卷（1021年），法蒂玛王朝

---

**一、香农的定理**

第四十二年，三月十七日，紫色黄昏。我在阿尔法平原东缘的通讯站遇到一位信息论学者。

通讯站建于某个战争时期，用于截获和解密敌方信号。战争早已结束（具体是哪场战争，谁与谁为敌,已无人记得），但设备仍在运转：天线缓慢旋转，接收器发出嗡嗡声，纸带从电传打字机中吐出，印满随机的字符。

学者在地下室工作。墙上贴着克劳德·香农的照片和他的熵公式：

**H(X) = -Σᵢ p(xᵢ) log₂ p(xᵢ)**

他正在计算天书的信息熵。

---

**二、信息量的定义**

他给我看一本教科书：《信息论基础》。我们从第一章开始。

**定义1（信息量）**：一个事件 x 的信息量定义为：

I(x) = -log₂ p(x)

其中 p(x) 是事件发生的概率。单位：比特（bit）。

**解释**：概率越小的事件，一旦发生，提供的信息越多。极端情况：
- 如果 p(x) = 1（必然事件），则 I(x) = 0（无信息）
- 如果 p(x) = 0.5，则 I(x) = 1 bit
- 如果 p(x) = 1/1024，则 I(x) = 10 bits

**例**：投一枚公平硬币，结果"正面"的信息量是 -log₂(0.5) = 1 bit。

**定义2（熵）**：随机变量 X 的熵是其信息量的期望：

H(X) = E[I(X)] = -Σᵢ p(xᵢ) log₂ p(xᵢ)

**性质**：
1. H(X) ≥ 0，当且仅当 X 是确定性变量（某个 p(xᵢ) = 1）时等号成立
2. H(X) ≤ log₂ n，其中 n 是 X 可能取值的数量；当且仅当 X 是均匀分布时等号成立

**解释**：熵衡量不确定性。均匀分布的熵最大——每个结果等可能，我们完全不知道会发生什么。确定性分布的熵为零——我们已经知道结果。

---

**三、巴别图书馆的熵**

"现在，"学者说，"考虑天书。"

他翻到笔记本的某一页：

**问题**：假设天书在巴别图书馆的某一本书中。图书馆共有 N = 25^(1,312,000) 本书，每本书等可能是天书。天书的位置（用哪本书编码）的熵是多少？

**解答**：设 X 为"天书的位置"这个随机变量。X 取值为 {1, 2, ..., N}，每个值的概率为 1/N。则：

H(X) = -Σᵢ (1/N) log₂(1/N) = -N · (1/N) · log₂(1/N) = log₂ N

计算：log₂(25^(1,312,000)) = 1,312,000 · log₂ 25 ≈ 1,312,000 · 4.644 ≈ 6,093,000 bits

即，指定天书在图书馆中的位置需要大约 **6百万比特** 的信息。

"这是熵的第一个悖论，"学者说。"我们需要6百万比特来'定位'天书。但天书据说包含一切信息——宇宙的全部知识。宇宙的信息量是多少？"

他翻到下一页：

**估算**：可观测宇宙的总信息量。

设宇宙包含约 10^80 个质子（贝肯斯坦-霍金估算）。每个质子携带的信息量受其康普顿波长和黑洞熵限制约束，粗略估计每个粒子约 10^2 bits（考虑位置、动量、自旋等自由度）。

总信息量上界：≈ 10^82 bits ≈ 2^272 bits

因此：log₂(宇宙信息) ≈ 272 bits

"这意味着，"学者说，"用272比特，我们可以指定宇宙的完整状态——每个粒子的位置和动量。但用6百万比特，我们只能指定天书在图书馆中的位置。"

"所以定位天书比定义宇宙更困难？"

"是的。或者说，如果天书真的包含一切，那么'在哪一本书中'这个问题本身包含的信息量，远超宇宙的总信息量。这是第一个矛盾。"

---

**四、完备性的悖论**

"第二个悖论更深刻，"学者翻到下一节。

**问题**：假设我们找到了天书。天书的内容的熵是多少？

**情况A**：天书是一本特定的书，包含特定的信息（如"宇宙的统一理论"）。

则天书的熵 = 这个特定信息的熵 = 有限值（假设 h bits）。

**情况B**：天书"包含一切"，即包含所有可能的信息。

如何理解"包含一切"？

**解释1**：天书同时包含所有 25^(1,312,000) 本可能书籍的内容。

但这是物理上不可能的——一本书无法同时包含 10^1,834,097 本书的内容（空间限制）。

除非...天书处于量子叠加态（参见第8篇）？

在这种情况下，天书的状态是：

|T⟩ = (1/√N) Σᵢ |Bᵢ⟩

其中 |Bᵢ⟩ 是第 i 本书。这个状态的冯·诺依曼熵是：

S = -Tr(ρ log ρ) = -Σᵢ (1/N) log(1/N) = log N ≈ 6百万 bits

**解释2**：天书不是同时包含所有信息，而是"等概率地可能包含任何信息"。

从信息论角度，这意味着：在我们观察天书之前，它的内容是一个均匀分布的随机变量 C，取值为所有可能的 1,312,000字符序列。

C 的熵：H(C) = log₂(25^(1,312,000)) ≈ 6百万 bits

这是可能的最大熵——完全的不确定性。

"但熵的含义是什么？"学者问。"高熵意味着高不确定性，意味着我们对内容一无所知。一个最大熵的对象，从信息论角度，等价于随机噪音。"

他在黑板上画了两个序列：

**序列1**：AAAAAAA... （1,312,000个A）
**序列2**：QXJLBWZ... （1,312,000个随机字符）

"序列1的熵接近零——高度有序，高度可预测。我们只需知道第一个字符和重复规则，就能重构整个序列。压缩后，它只需几个比特。

序列2的熵接近最大值——完全随机，不可压缩。它需要全部 6百万比特来存储。

如果天书'包含一切'意味着它等概率地可能是任何序列，那么天书等价于序列2——白噪音。"

"但白噪音不包含任何有意义的信息。"

"准确地说，白噪音包含**最多的信息**（从香农意义上），但**没有意义**（从语义学意义上）。信息论不关心意义——它只关心不确定性的减少。一个完全随机的序列，从信息论角度，是最'丰富'的——因为你无法预测它的任何部分，每个比特都提供1比特的新信息。

但从人类角度，白噪音是空洞的，因为它不编码任何结构、任何规律、任何知识。"

**悖论**：如果天书包含一切，它的熵最大，因此它等价于白噪音——最大的信息量，最少的意义。

---

**五、柯尔莫哥洛夫复杂度**

"也许，"学者说，"我们用错了信息量的定义。香农熵衡量的是统计不确定性，不是内容的复杂度。有另一个定义：柯尔莫哥洛夫复杂度。"

他翻到教科书的高级章节。

**定义3（柯尔莫哥洛夫复杂度）**：字符串 s 的柯尔莫哥洛夫复杂度 K(s) 是能生成 s 的最短程序的长度（在某个通用图灵机上）。

**例**：
- s₁ = "AAAA...A" (n个A)：K(s₁) ≈ log n（程序："输出n个A"）
- s₂ = π 的前n位小数：K(s₂) ≈ c（常数，程序："计算π的n位"）
- s₃ = 随机字符串：K(s₃) ≈ n（不可压缩，程序就是字符串本身）

**性质**：
1. K(s) ≤ |s| + c（任何字符串的最短程序不超过字符串本身加常数）
2. 大多数长度为n的字符串满足 K(s) ≈ n（不可压缩性定理）
3. 不存在算法能计算任意字符串的K(s)（不可计算性）

"现在考虑天书，"学者说。"如果天书'包含一切'，它的柯尔莫哥洛夫复杂度是多少？"

**情况A**：天书是最大压缩的。

存在一个非常短的程序 P（可能只有几百比特），它能生成天书的全部内容。在这种情况下，K(T) ≈ |P| << |T|。

天书虽然很长（1,312,000字符），但它的"本质"非常简单——就像π，虽然有无穷多位小数，但可以用简短的算法定义。

但这意味着天书的内容是高度结构化的，是某个简单规律的展开。这与"包含一切"矛盾——如果一切都遵循同一个规律，那不是"一切"，而是"一"。

**情况B**：天书是不可压缩的。

天书的内容是真正随机的，没有任何模式，没有任何结构。K(T) ≈ |T| ≈ 6百万比特。

在这种情况下，天书等价于随机数表——它"包含"所有可能的子序列（以统计意义），但不包含任何可以被简洁表达的知识。

"两种情况都导致矛盾，"学者总结。"如果天书可压缩，它不包含一切；如果天书不可压缩，它不包含任何（有结构的）知识。"

---

**六、编码定理**

学者在黑板上写下香农的源编码定理：

**定理（香农）**：设信源产生独立同分布的符号，熵为 H。则：

1. 不存在无损压缩算法能将平均码长压缩到低于 H。
2. 存在压缩算法使平均码长任意接近 H。

"这个定理说，"学者解释，"熵是信息的不可压缩的核心。你可以去除冗余（通过压缩），但最终你会碰到一个下界——熵。"

"应用到天书：假设天书确实包含一切知识。所有这些知识的总熵是多少？"

他开始计算：

**人类所有书籍**的信息量：
- 假设人类历史上写过约 1亿本书
- 每本书平均 10^5 个字（约300页）
- 使用26个字母 + 标点，约50个符号
- 熵（假设每个字符约2比特，考虑自然语言的冗余）：2 bits/字符

总量：10^8 本 × 10^5 字/本 × 2 bits/字 ≈ 2×10^13 bits ≈ 2TB

"这是人类所有书籍的信息量。大约2TB——一个现代硬盘的容量。"

"现在，如果天书要'包含'这一切，它需要多大？"

**情况A**（无损压缩）：至少 2TB。

**情况B**（有损压缩）：可以更小，但会丢失细节。

"但巴别图书馆的一本书只有 1,312,000 字符 × log₂ 25 ≈ 6百万比特 ≈ 0.7 MB。"

"0.7 MB 无法无损地包含 2TB 的信息。这是数学上不可能的。"

"所以天书无法包含所有人类知识？"

"如果天书是一本物理的书，受字符数限制——是的。但也许天书不是在内容上包含一切，而是在结构上指向一切？"

---

**七、指针的悖论**

"考虑这个可能性，"学者说。"天书不直接包含所有信息，而是包含对所有信息的索引或指针。"

类似于互联网上的一个网页，它不包含所有内容，但通过超链接指向所有其他页面。

"这类似于第7篇提到的索引之书。但索引本身需要多大？"

**计算**：假设天书索引所有人类知识。

- 人类知识项数：估计约 10^12 个独立的"事实"或"概念"
- 每个事实需要一个指针（地址）

如果使用二进制索引，我们需要 log₂(10^12) ≈ 40 bits/指针。

总索引大小：10^12 × 40 bits ≈ 5 TB

"索引比被索引的内容更大！这又是一个悖论。"

"或者，"他继续，"天书使用某种分形或递归的索引系统。每个条目不是直接指向一个事实，而是指向一个规则，这个规则生成一类事实。"

类似于用一个公式（如 πr²）代替所有圆的面积的列表。

"在这种情况下，天书的大小可以很小——只需包含足够的'公理'或'生成规则'。但这又回到了柯尔莫哥洛夫复杂度的情况A：天书是一个压缩算法。"

"而压缩意味着选择——选择保留什么规律，丢弃什么细节。压缩是有损的，至少在语义层面上。"

---

**八、互信息与独立性**

"最后一个角度，"学者翻到笔记本的最后一页。"互信息。"

**定义4（互信息）**：两个随机变量 X 和 Y 的互信息定义为：

I(X; Y) = H(X) + H(Y) - H(X,Y)

它衡量 X 和 Y 之间共享的信息量。

**性质**：
- I(X; Y) = 0 当且仅当 X 和 Y 独立
- I(X; Y) = H(X) 当且仅当 X 完全由 Y 决定

"现在考虑：设 T 为天书的内容，U 为宇宙的状态。天书与宇宙的互信息是多少？"

**情况A**：天书完全描述宇宙。

则 I(T; U) = H(U)（天书包含关于宇宙的全部信息）。

但这意味着，知道T后，宇宙的不确定性降为零——我们可以从天书预测宇宙的每个细节。这与量子力学的不确定性原理矛盾（第8篇）。

**情况B**：天书与宇宙独立。

则 I(T; U) = 0。

这意味着天书不包含任何关于宇宙的信息——它是一个与现实无关的文本。

"两个极端都不对，"学者说。"真实情况应该在中间：天书包含关于宇宙的部分信息，但不是全部。它减少了不确定性，但不消除不确定性。"

"但这意味着天书不'包含一切'。"

"是的。从信息论角度，'包含一切'是不可能的——除非'一切'的信息量恰好等于天书的容量。但如果天书有有限的容量（如 6百万比特），而宇宙的信息量是更大的或无限的，那么天书最多是一个有损的摘要。"

---

**九、零熵的极限**

"有一个例外，"学者说。"如果天书的熵为零。"

他在黑板上写：

**H(T) = 0**

"熵为零意味着天书的内容是完全确定的——没有任何不确定性，没有任何随机性。从统计角度，它只有一个可能的状态。"

"什么样的书满足这个条件？"

"两种："

**1. 空书**：不包含任何字符，或所有字符相同（如 AAA...A）。这种书可以用零信息描述（只需说"空"或"全A"）。

**2. 完全确定的书**：内容被某个已知的规则完全决定（如"π的所有小数位"）。这种书的熵为零，因为一旦你知道规则，就没有不确定性。

"π 的例子很有趣，"学者说。"π 是无理数，小数位无限且不循环。从某种意义上，π '包含'无限的信息。但从另一个意义上，π 的柯尔莫哥洛夫复杂度是有限的——你可以用一个简短的程序计算它的任意位。因此，π 的信息熵为零（因为完全可预测），但它的信息容量是无限的（因为有无限多位）。"

"天书可能类似于π ——一个由简单规则生成的无限序列，熵为零，但表面上包含一切？"

"也许。但π 的'包含一切'是假象。π 中确实会出现任何有限的数字序列（如你的生日、你的电话号码），但这是统计必然性，不是设计。它不'知道'你的生日——它只是盲目地生成所有可能的序列，因为它无限长。"

"所以零熵的'包含一切'是无意识的包含——通过穷举，而非理解。"

"是的。"

---

**十、信息之外**

傍晚，通讯站的天线停止了旋转。电传打字机停止了打印。一切归于沉默。

学者关掉所有设备，说："信息论告诉我们天书的极限。但也许天书不在信息论的框架内。"

"什么意思？"

"香农的信息论关心的是符号的传输——发送者、信道、接收者。它不关心意义。一个包含'aaaa'的消息和一个包含'rose'的消息，如果概率相同，具有相同的信息量——即使后者在英语中有意义，前者没有。"

"但天书的'包含一切'也许不是符号层面的包含，而是意义层面的包含。它不需要列出所有事实，只需提供理解所有事实的钥匙。"

"那这个钥匙是什么？"

"我不知道。也许是一种语言，一种思维方式,一种观看世界的角度。也许读天书不是接收信息，而是学习如何生成信息——如何从有限的公理推导无限的定理。"

"那天书的信息量仍然是有限的（公理的集合），但它的'意义容量'是无限的（所有可推导的定理）。"

"是的。这类似于图灵机：一个有限的程序（有限比特）可以进行无限的计算（生成无限的输出）。也许天书是一个'语义图灵机'——一个能生成所有意义的有限程序。"

他在笔记本最后一页写道：

**天书的信息量 = 有限（程序本身）**
**天书的意义容量 = 无限（程序的可能输出）**
**但：意义不可测量。香农熵无法捕捉它。**

**因此：信息论可以证明天书（作为符号序列）的不可能性，但无法触及天书（作为意义生成器）的可能性。**

**寻找天书不是寻找信息，而是寻找理解。而理解的熵——如果有这样的概念——我们还没有公式来计算。**

---

**尾声**

我离开通讯站时，学者在纸带上打印了最后一条消息：

01001001 01100110 00100000 01111001 01101111 01110101
00100000 01100011 01100001 01101110 00100000 01110010
01100101 01100001 01100100 00100000 01110100 01101000
01101001 01110011 00101100 00100000 01111001 01101111
01110101 00100000 01101000 01100001 01110110 01100101
00100000 01100110 01101111 01110101 01101110 01100100
00100000 01110100 01101000 01100101 00100000 01100010
01101111 01101111 01101011 00101110

他说："这条消息的熵大约是300比特。如果你能将它转换为意义，你就理解了信息与理解之间的差距。"

我走了三天，才意识到那是ASCII编码。我解码得到：

"If you can read this, you have found the book."

但这不是天书。这只是一条关于天书的消息。

或者，也许每一条被解码的消息、每一次从符号到意义的转换、每一个理解的瞬间——这些都是天书的碎片？

也许天书不是一个信息量的总和，而是信息转化为意义的过程本身。

而这个过程，发生在每个阅读的行为中，每个理解的瞬间。

它的熵无法计算，因为它不在符号空间中，而在意识的空间中。

---

**【编者注】**

此文献附带一卷纸带，长度73米，印满二进制数字。经解码，前半部分是随机数（熵 ≈ 1 bit/bit），后半部分是重复的模式（熵 ≈ 0.1 bit/bit）。

最后300比特如文中所述，解码为："If you can read this, you have found the book."

关于信息论与天书的关系，现代信息论学者指出：香农熵确实无法捕捉"意义"——这是符号学和语义学的领域，不是信息论的领域。但香农本人从未声称信息论能解决意义问题。信息论是关于"通讯的可能性"，不是"理解的本质"。

有一个相关的结果：**齐普夫定律**（Zipf's Law），它发现自然语言中词频分布遵循幂律——少数词出现频率极高，大多数词很少出现。这个分布使自然语言的熵低于最大值（如果所有词等频），但高于最小值（如果只用一个词）。

如果天书是用某种"理想语言"写成的，这种语言的词频分布会是什么样？

**情况A**：均匀分布（所有词等频）→ 熵最大 → 类似白噪音 → 无意义

**情况B**：极端偏斜（只有一个词）→ 熵最小 → 完全冗余 → 无内容

真实的语言在两者之间——足够的结构使意义成为可能，足够的变化使交流成为必要。

也许天书的语言也是如此：在最大熵与零熵之间的某个"临界点"，在随机与确定之间的某个"相变"处。

而我们的语言——不完美、冗余、充满歧义——也许正是对那个临界点的粗糙近似。

我们每一次说话、每一次写作，都是在尝试抵达那个点。

而永远接近，但永不抵达。

**咿。**
